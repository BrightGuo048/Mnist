{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三层全连接神经网络实现手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据载入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root = root_dir\n",
    "        \n",
    "    def load_mnist(self, x_path, y_path):\n",
    "        with open(y_path, 'rb') as r:\n",
    "            magic, n = struct.unpack('>II', r.read(8))\n",
    "            labels = np.fromfile(r, dtype=np.uint8)\n",
    "            \n",
    "        with open(x_path, 'rb') as r:\n",
    "            magic, num, rows, cols = struct.unpack('>IIII', r.read(16))\n",
    "            images = np.fromfile(r, dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "        return images, labels\n",
    "    \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.load_mnist(\n",
    "            os.path.join(self.root, \"train-images.idx3-ubyte\"),\n",
    "            os.path.join(self.root, \"train-labels.idx1-ubyte\"))\n",
    "        x_test, y_test = self.load_mnist(\n",
    "            os.path.join(self.root, \"t10k-images.idx3-ubyte\"),\n",
    "            os.path.join(self.root, \"t10k-labels.idx1-ubyte\"))\n",
    "        \n",
    "        return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fully_Connect:\n",
    "    def __init__(self, num_in, num_out):\n",
    "        self.w = np.random.normal(size= (num_in, num_out), scale=0.01, loc=0)\n",
    "        self.b = np.random.normal(size= num_out, scale=0.01, loc=0)\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        \n",
    "    def infer(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.w) + self.b\n",
    "        self.y = out\n",
    "        return out\n",
    "    \n",
    "    def Gred(self, d_p):\n",
    "        d_c = np.dot(d_p, np.transpose(self.w))\n",
    "        self.w = self.w - lr * np.dot(np.transpose(self.x), d_p)\n",
    "        self.b = self.b - lr * d_p\n",
    "        return d_c    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "    \n",
    "    def infer(self, x):\n",
    "        self.x = x\n",
    "        out = np.maximum(self.x, 0)\n",
    "        return out\n",
    "    \n",
    "    def Gred(self, d_p):\n",
    "        d_c = d_p\n",
    "        p = np.isinf(self.x / self.x)\n",
    "        d_c[p] = 0\n",
    "        return d_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "        self.t = 0\n",
    "        self.y = 0\n",
    "        self.t_onehot = 0\n",
    "    \n",
    "    def infer(self, x, truth):\n",
    "        self.x = x\n",
    "        self.t = truth\n",
    "        \n",
    "        row_max = self.x.max(axis= 1)\n",
    "        row_max = row_max.reshape(-1, 1)\n",
    "        x = self.x - row_max\n",
    "        x_exp = np.exp(x)\n",
    "        x_sum = np.sum(x_exp, axis= 1, keepdims=True)\n",
    "        out = x_exp / x_sum\n",
    "        self.y = out\n",
    "    \n",
    "    def cal_loss(self):\n",
    "        one_hot = np.zeros_like(self.y)\n",
    "        one_hot[np.arange(batch), self.t] = 1.0 #one-hot code\n",
    "        self.t_onehot = one_hot\n",
    "        loss = - np.sum(np.log(self.y) * self.t_onehot) / batch\n",
    "        \n",
    "        if(loss == 'nan'):\n",
    "            print(self.y)\n",
    "            print(self.t_onehot)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def Gred(self):\n",
    "        d_c = 1.0 / batch * (self.y - self.t_onehot)\n",
    "        return d_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, in_num, num1, num2, num3):\n",
    "        self.x = 0\n",
    "        self.label = 0\n",
    "        self.fc1 = Fully_Connect(in_num, num1)\n",
    "        self.act1 = Activation()\n",
    "        self.fc2 = Fully_Connect(num1, num2)\n",
    "        self.act2 = Activation()\n",
    "        self.fc3 = Fully_Connect(num2, num3)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def forward(self, x, label):\n",
    "        f1 = self.fc1.infer(x)\n",
    "        a1 = self.act1.infer(f1)\n",
    "        f2 = self.fc2.infer(a1)\n",
    "        a2 = self.act2.infer(f2)\n",
    "        f3 = self.fc3.infer(a2) \n",
    "        self.softmax.infer(f3, label)\n",
    "        \n",
    "        loss = self.softmax.cal_loss()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        loss_d = self.softmax.Gred()\n",
    "        fc3_d = self.fc3.Gred(loss_d)\n",
    "        act2_d =self.act2.Gred(fc3_d)\n",
    "        fc2_d = self.fc2.Gred(act2_d)\n",
    "        act1_d = self.act1.Gred(fc2_d)\n",
    "        fc1_d = self.fc1.Gred(act1_d)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    loss = 0\n",
    "    for e in range(epoch):\n",
    "        for iter in range(math.ceil(train_images.shape[0] / batch)):\n",
    "            x = train_images[iter*batch:(iter+1)*batch,:]\n",
    "            label = train_labels[iter*batch:(iter+1)*batch]\n",
    "            loss = net.forward(x, label)\n",
    "            net.backward()\n",
    "        loss_list.append(loss)\n",
    "        print(\"epoch = {} loss = {}\".format(e+1, loss))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制loss曲线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_loss(loss_list):\n",
    "    y_axis = loss_list\n",
    "    x_axis = [i for i in range(len(loss_list))]\n",
    "    plt.plot(x_axis, y_axis)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"D:mnist//\"\n",
    "lr = 0.001\n",
    "batch = 200\n",
    "im_scale = 784\n",
    "epoch = 500\n",
    "\n",
    "#500 neurons in the hidden layer1,\n",
    "#300 neurons in the hidden layer2,\n",
    "#10 neurons in the hidden layer3\n",
    "cell_num1 = 500\n",
    "cell_num2 = 300\n",
    "cell_num3 = 10\n",
    "\n",
    "loss_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataloader = Dataloader(file)\n",
    "train_images, train_labels, test_images, test_labels = dataloader.load_data()\n",
    "print(\"训练数据尺寸\\n 图像 {} 标签{}\".format(train_images.shape, train_labels.shape))\n",
    "print(\"测试数据尺寸\\n 图像 {} 标签{}\".format(test_images.shape, test_labels.shape))\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training and evaluating!！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = Net(train_images.shape[1], cell_num1, cell_num2, cell_num3)\n",
    "train(net)\n",
    "draw_loss(loss_list)\n",
    "evaluate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
